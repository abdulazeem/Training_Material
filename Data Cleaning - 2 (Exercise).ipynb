{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Concatenation\n",
    "    \n",
    "1) Create two simple data frames for concatenation\n",
    "\n",
    "2) Combine data row wise using pd.concat() function. Observe the index column.\n",
    "\n",
    "3) Reset the index by passing ignore_index=True to the pd.concat function.\n",
    "\n",
    "4) Combine data column wise usind pd.concat() with axis=1 \n",
    "\n",
    "5) Rename the column names of the combined data using .columns method\n",
    "\n",
    "6) Change the df1 and df2 data sets by adding an additional cell and check the above concatenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Combine the attendance data of Employees available in different sets\n",
    "\n",
    "1) Combine all given datasets and check the shape before and after combining the data to confirm the combination.\n",
    "\n",
    "2) Combine only 10 rows from each set\n",
    "\n",
    "\n",
    "**Data:**\n",
    "\n",
    "absent_seta\n",
    "\n",
    "absent_setb\n",
    "\n",
    "absent_setc\n",
    "\n",
    "absent_setd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Use Glob function to import all data files\n",
    "\n",
    "Glob module has a function called glob that takes a pattern and returns a list of the files in the working directory that match that pattern.\n",
    "\n",
    "\n",
    "1) Write a pattern to extract all the csv files from our current folder.\n",
    "\n",
    "2) Write a pattern to extract only the below filenames from our current folder.\n",
    "\n",
    "3) Import a single data file from the extracted list\n",
    "\n",
    "\n",
    "\n",
    "https://www.poftut.com/python-glob-function-to-match-path-directory-file-names-with-examples/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['absent_seta.csv', 'absent_setb.csv', 'absent_setc.csv', 'absent_setd.csv']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "glob.glob('absent_set?*.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Iterating and concatenating all matches\n",
    "\n",
    "Now that you have a list of filenames to load, you can load all the files into a list of DataFrames that can then be concatenated. Write a for loop to extract data from all the filenames extracted and concatenate row wise.\n",
    "\n",
    "absent_seta\n",
    "\n",
    "absent_setb\n",
    "\n",
    "absent_setc\n",
    "\n",
    "absent_setd\n",
    "\n",
    "1) Start with an empty list called data_set.\n",
    "\n",
    "2) iterate through each of the filenames\n",
    "\n",
    "3) Read each filename into a DataFrame, and then append it to the data_set\n",
    "\n",
    "4) Concatenate this list of DataFrames using pd.concat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5: Data Types \n",
    "\n",
    "The billing_types.csv dataset contains information about how much a customer is billed, tipped, and few personal details about the customer. \n",
    "\n",
    "1) Observe the datatype of each column using the .info() method, along with the total memory usage.\n",
    "\n",
    "2) The gender and smoking information columns can be converted to categorical datatype using astype('category') method to the column . Check the memory usage with .info method and observe the reduced memory usage.\n",
    "\n",
    "3) Change the datatype of total_bill and tip information to integer. This can be done in three ways depending on the data available.\n",
    "\n",
    "    a) convert to integer using astype('int') method\n",
    "\n",
    "    b) if the data has floating point numbers, then convert using astype('float') method\n",
    "\n",
    "    c) if the data has errors, which might be inclusion of some dashed or strings, then use the function pd.to_numeric(column, errors='coerce') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6: Using Regular Expressions \n",
    "\n",
    "When working with data, it is necessary to write a regular expression to look for properly entered values. This will validate the data to be in the format which we intend. \n",
    "\n",
    "# re.match(pattern, data)\n",
    "\n",
    "Use .span(), string, and .group() methods along with match to observe the start-end positions, string part passed to function, part of the string where there was a match respectively.\n",
    "\n",
    "1) Match the word 'John1' by passing exactly same word in the pattern. Check also by writing different numbers infront of John.\n",
    "\n",
    "2) Match a pattern to validate the total amount to be in the form $123.45 (sample amount up to two decimals only)\n",
    "\n",
    "3) Match a pattern to validate the entry of phone number in a country to be of the form 123-456-7861 (sample number)\n",
    "\n",
    "4) Match a pattern to validate password which should contain atleast one capital letter, one special character, one digit, with a 6-12 character length password\n",
    "\n",
    "# re.findall(pattern, data)\n",
    "\n",
    "5) Extract number from the string 'There are 20 different types of items in the workshop'\n",
    "\n",
    "6) Extract numbers from the string 'The height and weight of the individual are 156.23 cm and 38.5 kg'\n",
    "\n",
    "https://www.w3schools.com/python/python_regex.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7: Difference between re.sub(regular expression function) and .replace string method\n",
    "    \n",
    "**Single replacement**\n",
    "\n",
    "1) For the given string, 'This is a new place', use string method .replace to replace the spaces with underscores.\n",
    "\n",
    "2) For the given string, 'This is a new place', use regular expression function re.sub() to replace the spaces with underscores.\n",
    "\n",
    "**function format**: re.sub(pattern, str to be replaced, data) \n",
    "\n",
    "**Multiple replacements**\n",
    "3) Similarly, for the given string 'The lion, tiger, and leopard all belong to cat family' replace the animal names with 'animal'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8: Use Custom Functions to Clean Data\n",
    "\n",
    "The'billing_types.csv' data set has a Gender column. Write a function that will recode 'Female' to 0, 'Male' to 1, and return np.nan for all entries of 'Gender' that are neither 'Female' nor 'Male'.\n",
    "\n",
    "Write a simple function for one cell, and then use .apply() method to apply it on the complete column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9: Use Lambda Functions to Clean Data\n",
    "\n",
    "\n",
    "1) Use lambda function along with .replace method to remove the dollar sign from the price column\n",
    "\n",
    "2) Use lambda function with regular expression to remove the dollar sign\n",
    "\n",
    "Use sales_sub1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 10: Dealing with Missing Data\n",
    "    \n",
    "1) Check the missing values using .info() and .isnull() methods.\n",
    "\n",
    "2) Drop duplicate data from the dataset using .dropduplicates() method and re-check the shape of the dataset.\n",
    "\n",
    "3) Find the percentage of missing data\n",
    "\n",
    "4) Use fillna with statistical values to fill the missing data.\n",
    "\n",
    "    a) Categorical data: .fillna(method='ffill')\n",
    "    \n",
    "    b) Numerical data : .fillna(np.mean(data))\n",
    "    \n",
    "5) Use interpolate(method='linear', method_direction='forward') for numerical data\n",
    "\n",
    "6) Fill the missing values in bulk for categorical and numerical columns\n",
    "    \n",
    "7) Use .dropna(how='any') or .dropna(how='all') and argument axis =0/1 to drop column or row\n",
    "\n",
    "8) Use asserts to test the data\n",
    "\n",
    "Use billing_types.csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
