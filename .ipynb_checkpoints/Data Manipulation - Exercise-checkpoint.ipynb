{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'C:\\Users\\user\\Desktop\\DS - Course\\File - 7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Stacking and Unstacking\n",
    "\n",
    "#### 1) Stack and Unstack a file\n",
    "    a) Read the file signups.csv\n",
    "    \n",
    "    b) set the weekday and city as index \n",
    "    \n",
    "    c) Now unstack the index using df.unstack(level='index_name')\n",
    "    \n",
    "    d) Now split the index again by stacking it back .. Use df.stack(level='index_name')\n",
    "    \n",
    "    e) Swap the levels of the index using .swaplevel(0,1)\n",
    "    \n",
    "    f) Sort the index using .sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 - Grouping categorical variables\n",
    "\n",
    "#### 1) Grouping using boolean indexing\n",
    "    \n",
    "    a) For the given sales_heirarchy.csv file find the sum of each numerical column for 'CA' state.\n",
    "\n",
    "#### 2) Grouping using groupby\n",
    "\n",
    "    a) Perform the same operation, as above, for all states using groupby function. Use .groupby method\n",
    "    \n",
    "    b) Perform the same operation, for only 'eggs' column using groupby.\n",
    "    \n",
    "#### 3) Read the titanic.csv files and performt the following operations:\n",
    "    \n",
    "    a) How many people from each pclass survived on the ship?\n",
    "    \n",
    "    b) Grouping Multiple Columns: How many people of various 'embarked' category of various 'pclass' survived on the ship\n",
    "    \n",
    "###### The 'pclass' column identifies which class of ticket was purchased by the passenger and the 'embarked' column indicates at which of the three ports the passenger boarded the Titanic. 'S' stands for Southampton, England, 'C' for Cherbourg, France and 'Q' for Queenstown, Ireland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Grouping by another Series\n",
    "\n",
    "We have two data sets, one from Gapminder.org to investigate the average life expectancy (in years) at birth in 2010 for the 6 continental regions. To do this you'll read the life expectancy data per country into one pandas DataFrame and the association between country and region into another. By setting the index of both DataFrames to the country name, you'll then use the region information to group the countries in the life expectancy DataFrame and compute the mean value for 2010.\n",
    "\n",
    "a) gapminder_tidy.csv\n",
    "\n",
    "b) Region.csv\n",
    "\n",
    "#### Things to do:\n",
    "    \n",
    "    1) Read both csv files using index as countries, as to group one dataframe using other data series, the index must be matching.\n",
    "    \n",
    "    2) Check the dimensions of each the above file, and length of unique elements in the Country column for each.\n",
    "    \n",
    "    3) As per the observation, the gapminder data needs to be converted into pivot table with only life expectancy as the required column.\n",
    "    \n",
    "    4) Use the group by method with region, to find the mean for each region\n",
    "    \n",
    "    5) Use the group by method with region, to find the mean for 1964 and 1965"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Multiple Aggregates of Multiple Columns\n",
    "\n",
    "#### 1) Group passengers on the Titanic by 'pclass' and aggregate the 'age' and 'fare' columns by the functions 'max' , 'mean, and 'median'\n",
    "    a) Find the max, mean, and median of age and fare columns based on their 'pclass' category.\n",
    "    \n",
    "    b) Slice to return the maximum age in each class\n",
    "    \n",
    "    c) Slice to return the median fare in each class\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5: Aggregating on index levels/fields\n",
    "\n",
    "Now suppose our dataframe has as multi-level row index, the individual levels can be used to perform the groupby.\n",
    "\n",
    "#### 1) Create multi level dataframe of the columns Year, region, and Country. \n",
    "\n",
    "#### 2) Group the dataframe by region and Country and find the mean of the rest of the columns\n",
    "    \n",
    "#### 3) Group the dataframe by Year and region, and find the total population, mean life rate, and range of gdp for each group.\n",
    "    \n",
    "        a) Group the data frame by Year and region using groupby\n",
    "        \n",
    "        b) Define a function to find the range of a series\n",
    "        \n",
    "        c) Create a dictionary of aggregator to perform the group functions.\n",
    "        \n",
    "        d) Pass the aggregator to the grouped dataframe using .agg\n",
    "    \n",
    "#### 4) From the above grouped data, access the 1964 population data for all regions.\n",
    "    \n",
    "#### 5) From the above grouped data, access the complete data for 'America' for all years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6: Grouping on function of the index\n",
    "\n",
    "Grouping function can also be peformed on a transformed column. In this case we will do the grouping operation on the parsed date column.\n",
    "\n",
    "1) Red the sales2.csv file along with index as Date column.\n",
    "\n",
    "2) Parse the date column using strftime and use it for grouping\n",
    "\n",
    "3) Find the sum of Units for each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7: Group and Transform: Identify the Outlier\n",
    "\n",
    "We can transform a column based on operations performed on each group of a series. In this example we will use gapminder data to detect the outliers in the . The z-score is useful to find the outliers: a z score value of +/- 3 is generally considered an outlier.\n",
    "\n",
    "1) For the given gapminder_tidy.csv file, identify the outliers for the life column. Use zscore as a measure to identify the outliers.\n",
    "\n",
    "2) Use the identified outlier as a filter to the original gapminder data to identify the complete rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8: Group and Transform - Impute Missing Values\n",
    "\n",
    "Fill the missing values in the height column by grouping the dataframe based on Gender and Ageyears.\n",
    "\n",
    "1) Write a function to impute median values in for a series.\n",
    "\n",
    "2) Group the dataframe in appropriate categories to fill the missing values in height column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9: Grouping and Filtering with apply()\n",
    "\n",
    "The .apply() method will handle the iteration over individual groups and then re-combine them back into a Series or DataFrame.\n",
    "\n",
    "For the given titanic.csv data, find the following info.\n",
    "\n",
    "#### 1) How many passengers from the C group survived?\n",
    "\n",
    "#### 2) How many male and female passengers from the C group survived?\n",
    "\n",
    "    a) Group the dataframe by 'gender' column\n",
    "    \n",
    "    b) write a custom function to apply to the grouped data. The custom function should extract the number of C passenger information from the cabin column and should be used as index along with the survived column.\n",
    "    \n",
    "    c) Use .apply to apply the function to the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 10: Grouping and Filtering with .filter()\n",
    "\n",
    "\n",
    "Groupby function can also be used with .filter(). In this exercise, you'll take the February sales data and remove entries from companies that purchased less than or equal to 35 Units in the whole month.\n",
    "\n",
    "First, you'll identify how many units each company bought for verification. Next you'll use the .filter() method after grouping by 'Company' to remove all rows belonging to companies whose sum over the 'Units' column was less than or equal to 35. Finally, verify that the three companies whose total Units purchased were less than or equal to 35 have been filtered out from the DataFram\n",
    "\n",
    "1) Find the total number of units sold by each company\n",
    "\n",
    "2) Filter out the entries of companies whose total Units sold were less than 35. Use .filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 11: Grouping and Filtering with .map\n",
    "\n",
    "You have seen how to group by a column, or by multiple columns. \n",
    "\n",
    "In this exercise your job is to investigate survival rates of passengers on the Titanic by 'age' and 'pclass'. In particular, the goal is to find out what fraction of children under 10 survived in each 'pclass'. You'll do this by first creating a boolean array where True is passengers under 10 years old and False is passengers over 10. You'll use .map() to change these values to strings.\n",
    "\n",
    "Finally, you'll group by the under 10 series and the 'pclass' column and aggregate the 'survived' column. The 'survived' column has the value 1 if the passenger survived and 0 otherwise. The mean of the 'survived' column is the fraction of passengers who lived.\n",
    "\n",
    "1) Create a mapping of age column as 'under 10' and 'above 10' based on their age.\n",
    "\n",
    "2) Find the number of survivors based on age group\n",
    "\n",
    "3) Find the number of survivors based on age group and pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
